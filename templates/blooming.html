<!DOCTYPE html>
<html>
<head>
	<title>Kat Sullivan</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta charset="utf-8"> 
	<link rel="stylesheet" type="text/css" href="../stylesheets/home.css">
	<link rel="stylesheet" type="text/css" href="../stylesheets/aether.css">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
</head>
<body>
	<div class="row">
		<h2 id="projects" onclick="myFunction()" class="dropbtn column">Projects</h2>
  		<h2 id="mocap" class="column"><a href="mocap.html">Motion Capture</a></h2>
		<h2 id="about" class="column"><a href="home.html">Home</a></h2>
	</div>
	<div id="myDropdown" class="dropdown-content">
    		<a href="aether.html">Aether</a>
    		<a href="torn.html">Torn</a>
    		<a href="ltc.html">Liable to Change</a>
    		<a href="blooming.html">Blooming</a>
    		<a href="terror.html">Near Terror</a>
  	</div>
		<div class="content">
		<h2>Blooming</h2>
		<iframe src="https://player.vimeo.com/video/281745714?portrait=0" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
		<p><a href="https://vimeo.com/281745714">Blooming</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

		<h3>Blooming highlights the importance of human presence and physical connection in our lives.<br>
<br>
It is an audio-visual interactive installation that responds to physical contact between two to three participants. It takes the form of a life-size 3D cherry blossom tree, a common symbol of social ties and of the transience of life in East Asian culture. <br>
<br>
As a response to participants’ heart rates, gestures, and skin-to-skin contact as they hold hands or embrace, the tree will flourish in peak bloom and will even release petals. When participants let go, the tree will return to its pre-bloom state. The colors of the cherry blossom flowers change based on participants' heart rates as they interact each other (the faster the heartbeats, the redder the tonality; the slower the heartbeats, the whiter the tonality). In addition to the tree’s visual response, sounds are also modulated according to the tree’s different stages: pre-bloom, blooming, maturing (petals falling).<br>
<br>
For my role, I wrote the algorithms that determined the level of contact between users using the Kinect camera and a custom machine learning algorithm. Depending on the level of contact, I would trigger different visuals with my code.</h3>

	<img src="../images/blooming.jpeg">
	<img src="../images/blooming2.jpg">
	<img src="../images/blooming3.jpg">
<p>
<h3>Credits</h3></br>
Commissioned and Supported by: Nokia Bell Labs, New Museum NEW INC</br>
Created and Directed by: Lisa Park</br>
Sensor Development & Collaboration: Gang Huang (Nokia Bell Labs)</br>
Technical Consultant: Sensorium Works</br>
Technical Lead: Todd Bryant</br>
3D Petals: Capitan Alegria</br>
3D Assets: Jeremy Thompson</br>
Heart rate Monitor programming: Ji Lee</br>
Gesture Tracking programming: Kat Sullivan</br>
Original Music by: Antfood</br>
</br>

<h3>Tools used</h3></br>
Kinect Sensor</br>
Python, Cinder, and Max/MSP,Jitter</br>
</br>
</br>

<h3>Exhibitions</h3></br>
April 29–June 2, 2018</br>
Only Human</br>
Presented by NEW INC and Nokia Bell Labs</br>
Mana Contemporary</br>
Jersey City, NJ</br>
</br>
<h3>Selected Press</h3></br>
2017 – <a class="press" href="https://www.wired.com/story/bell-labs-eat-only-human-mana-contemporary/" target="_blank">WHAT ARTISTS CAN TEACH US ABOUT MAKING TECHNOLOGY MORE HUMAN</a>, Wired</br>
</br>
</br>
</div>
<script>
		/* When the user clicks on the button, 
		toggle between hiding and showing the dropdown content */
		function myFunction() {
		  document.getElementById("myDropdown").classList.toggle("show");
		  console.log("here");
		}

	</script>

</body>
</html>